import os
import json
import time
import requests
from supabase import create_client
from dotenv import load_dotenv

load_dotenv('.env.local')

SUPABASE_URL = os.getenv("NEXT_PUBLIC_SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not SUPABASE_URL or not SUPABASE_KEY or not GEMINI_API_KEY:
    print("Error: Environment variables missing.")
    exit(1)

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

def generate_headlines_batch(titles):
    """
    Generate headlines for a batch of titles using Gemini 2.5 Flash
    """
    prompt = """
    You are a witty and sensible editor for 'News Spectrum', a Gen-Z targeted news service like Newneek.
    Your goal is to rewrite hard news titles into engaging and conversational headlines, BUT maintain journalistic integrity.
    
    Rules:
    1. Tone: Casual and friendly, BUT informative.
    2. Style: Use short summaries.
    3. Prohibition 1: NEVER end with a noun (e.g., "ë…¼ëž€", "ê°œìµœ", "ë°œí‘œ"). Always use a complete sentence.
    4. Prohibition 2: NO CLICKBAIT. Do not exaggerate. Stick to the facts.
    5. Prohibition 3: NO VAGUE QUESTIONS. Do NOT use "ë¬´ìŠ¨ ì¼ì´ì•¼?", "ì•Œì•„ë³¼ê¹Œ?", "ê¶ê¸ˆí•´?", "ì–´ë–¤ ìƒí™©ì¼ê¹Œ?".
    6. Prohibition 4: NO FILLER PHRASES. Do NOT use "ì§€ê¸ˆ ì´ë ‡ëŒ€ìš”", "ì—¬ê¸° ë‹¤ ìžˆì–´ìš”", "ì•Œë ¤ë“œë¦´ê²Œìš”", "ëª¨ì•˜ì–´ìš”", "ë§Œë‚˜ë´ìš”". These sound fake.
    7. Fallback: If the input is vague (e.g., "Sports News"), just translate it naturally or say "ì£¼ìš” ì†Œì‹ì„ ì •ë¦¬í–ˆì–´ìš”."
    8. Length: Keep it short (under 45 chars).
    9. Language: Korean.
    10. Emojis: Allowed if relevant (use sparingly).
    11. Output: ONLY the list of headlines. NO introductory text. NO numbering.

    Examples:
    - Input: "â€˜ìµœì•…ì˜ ì°¸ì‚¬â€™ í™ì½© ì•„íŒŒíŠ¸ í™”ìž¬, í”¼í•´ í‚¤ìš´ ì›ì¸ì€ â€˜ëŒ€ë‚˜ë¬´ ë¹„ê³„â€™ì˜€ë‹¤?"
    - Output: "í™ì½© ì•„íŒŒíŠ¸ í™”ìž¬, â€˜ìµœì•…ì˜ ì°¸ì‚¬â€™ê°€ ëœ ì´ìœ "

    - Input: "Sports results and analysis"
    - Output: "ìŠ¤í¬ì¸  ê²½ê¸° ê²°ê³¼ì™€ ë¶„ì„ì„ ì •ë¦¬í–ˆì–´ìš”." (O)
    - Output: "ìŠ¤í¬ì¸  ì†Œì‹, ì—¬ê¸° ë‹¤ ìžˆì–´ìš”!" (X - Filler)

    - Input: "Social issues in UK"
    - Output: "ì˜êµ­ì˜ ì£¼ìš” ì‚¬íšŒ ì´ìŠˆë“¤ì„ ëª¨ì•˜ì–´ìš”." (O)
    - Output: "ì˜êµ­ ì‚¬íšŒ ë¬¸ì œ, ì§€ê¸ˆ ì´ë ‡ëŒ€ìš”!" (X - Filler)

    - Input: "â€œë‚´ ì§‘ì— ëˆ„ê°€ ì‚¬ëŠ”ì§€ ì•Œê³  ì‹¶ì–´!â€ â€˜ìž„ì°¨ì¸ ë©´ì ‘ ì œë„â€™ê°€ ëœ¨ê±°ìš´ ê°ìžë¡œ ë– ì˜¤ë¥¸ ì´ìœ "
    - Output: "ì „ì…‹ì§‘ êµ¬í•˜ê³  ì‹¶ìœ¼ë©´ ë©´ì ‘ë¶€í„° ë³´ë¼ê³ ìš”? ðŸ "

    - Input: "ì‚¬ìƒ ìµœê³  ì‹¤ì  ê¸°ë¡í•œ ì—”ë¹„ë””ì•„, â€˜AI ê±°í’ˆë¡ â€™ì— â€œì—”ë¹„ë””ì•„ëŠ” ë‹¤ë¥´ë‹¤?â€"
    - Output: "â€œAI? ê±°í’ˆ ë§žì•„. ì–¸ë¹Œë¦¬ë²„ë¸”.â€ ì—”ë¹„ë””ì•„ ì‚¬ìƒ ìµœê³  ì‹¤ì !"

    - Input: "ì œ2ì˜ ë‹·ì»´ë²„ë¸”? AI ë²„ë¸”ë¡  ë°˜ë³µë˜ëŠ” ì´ìœ ì™€ â€˜ìˆœí™˜ê±°ëž˜â€™ ë…¼ëž€ ë¶„ì„"
    - Output: "ì œ2ì˜ ë‹·ì»´ë²„ë¸”? AI ê±°í’ˆë¡ ê³¼ â€˜ìˆœí™˜ê±°ëž˜â€™ ë…¼ëž€"

    - Input: "ëˆ„ë¦¬í˜¸ 4ì°¨ ë°œì‚¬ ì„±ê³µ, ë¯¼ê°„ ê¸°ì—…ì´ ì´ë„ëŠ” â€˜ë‰´ ìŠ¤íŽ˜ì´ìŠ¤â€™ ì‹œëŒ€ ì²«ê±¸ìŒ ë—€ ê±°ë¼ê³ ?"
    - Output: "ëŒ€í•œë¯¼êµ­ì€ ëˆ„ë¦¬í˜¸ íƒ€ê³  â€˜ë‰´ ìŠ¤íŽ˜ì´ìŠ¤â€™ ì‹œëŒ€ë¡œ ê°‘ë‹ˆë‹¤ ðŸš€"

    - Input: "ê°ì‚¬ì› ìœ¤ì„ì—´ ì •ë¶€ ì˜ëŒ€ ì¦ì› ê°ì‚¬ ê²°ê³¼: â€œê·¼ê±°ë„ ì ˆì°¨ë„ ë¶€ì¡±í–ˆì–´!â€"
    - Output: "ìœ¤ì„ì—´ ì •ë¶€ ì˜ëŒ€ ì¦ì›, ê·¼ê±°ë„ ë¶€ì¡±í•œë° ë°€ì–´ë¶™ì˜€ë‹¤ê³ ?"

    - Input: "1050ì›ì§œë¦¬ â€˜ì´ˆì½”íŒŒì´ ì ˆë„â€™ ì‚¬ê±´, í•­ì†Œì‹¬ì´ â€˜ë¬´ì£„â€™ ì„ ê³ í•œ ì´ìœ "
    - Output: "â€˜ì´ˆì½”íŒŒì´ ì ˆë„â€™ ì‚¬ê±´ì˜ ê²°ë§: â€œë¬´ì£„ë¥¼ ì„ ê³ í•©ë‹ˆë‹¤.â€"

    Input Titles:
    """ + json.dumps(titles, ensure_ascii=False)

    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={GEMINI_API_KEY}"
    headers = {'Content-Type': 'application/json'}
    data = {
        "contents": [{"parts": [{"text": prompt}]}],
        "safetySettings": [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"}
        ]
    }
    
    for attempt in range(3):
        try:
            # Increased timeout to 300s as requested by user
            response = requests.post(url, headers=headers, json=data, timeout=300)
            
            if response.status_code != 200:
                print(f"API Error ({attempt+1}/3): {response.status_code} - {response.text}")
                if response.status_code == 429:
                    time.sleep(30)
                else:
                    time.sleep(5)
                continue
                
            try:
                result = response.json()
            except Exception as e:
                print(f"JSON Parse Error ({attempt+1}/3): {e}")
                print(f"Response Status: {response.status_code}")
                # Print first 1000 chars to see what's wrong
                print(f"Response Text: {response.text[:1000]}")
                time.sleep(5)
                continue

            if 'candidates' not in result or not result['candidates']:
                print(f"No candidates ({attempt+1}/3). Feedback: {result.get('promptFeedback', 'None')}")
                time.sleep(5)
                continue
                
            text = result['candidates'][0]['content']['parts'][0]['text'].strip()
            # Clean up markdown
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0]
            elif "```" in text:
                text = text.split("```")[1].split("```")[0]
                
            try:
                parsed = json.loads(text)
            except Exception:
                # Fallback: Parse line by line if not JSON
                lines = [line.strip() for line in text.split('\n') if line.strip()]
                parsed = []
                for line in lines:
                    # Skip intro lines
                    if line.endswith(':') or "Here are" in line or "Sure" in line or "ë‹¤ìŒì€" in line:
                        continue
                        
                    # Remove leading numbers (e.g., "1. ", "2. ")
                    if line[0].isdigit():
                        parts = line.split('.', 1)
                        if len(parts) > 1:
                            line = parts[1].strip()
                    parsed.append(line)
            
            # Handle list response (JSON list or parsed lines)
            if isinstance(parsed, list):
                # If we have more items than titles, maybe first line is still intro?
                if len(parsed) > len(titles):
                    parsed = parsed[-len(titles):]
                    
                if len(parsed) == len(titles):
                    return {titles[i]: parsed[i] for i in range(len(titles))}
                # If lengths don't match, try to map as many as possible
                min_len = min(len(parsed), len(titles))
                return {titles[i]: parsed[i] for i in range(min_len)}
                
                # Try to match by key if list of dicts
                if parsed and isinstance(parsed[0], dict) and 'headline' in parsed[0]:
                    return {item.get('title', ''): item.get('headline', '') for item in parsed}
            
            return parsed
            
        except Exception as e:
            print(f"Error ({attempt+1}/3): {e}")
            time.sleep(5)
            
    return {}

def main():
    print("Fetching topics for 2025-11-27...")
    
    response = supabase.table("mvp_topics") \
        .select("id, title, title_kr") \
        .eq("date", "2025-11-27") \
        .execute()
        
    topics = response.data
    print(f"Found {len(topics)} topics.")
    
    # Process in batches of 50
    batch_size = 50
    for i in range(0, len(topics), batch_size):
        batch = topics[i:i+batch_size]
        titles = [t['title_kr'] or t['title'] for t in batch]
        
        print(f"[{i+1}/{len(topics)}] Generating batch of {len(batch)}...")
        
        headlines_map = generate_headlines_batch(titles)
        
        if headlines_map:
            for t in batch:
                original_title = t['title_kr'] or t['title']
                new_headline = headlines_map.get(original_title)
                
                if new_headline:
                    # print(f"  {original_title[:20]}... -> {new_headline}")
                    supabase.table("mvp_topics") \
                        .update({"headline": new_headline}) \
                        .eq("id", t['id']) \
                        .execute()
            print(f"  Batch {i//batch_size + 1} completed.")
        else:
            print("  Batch failed.")
            
        # Rate limit friendly
        time.sleep(2)

if __name__ == "__main__":
    main()
