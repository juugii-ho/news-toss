import os
import json
import time
import google.generativeai as genai
from supabase import create_client, Client
from dotenv import load_dotenv
from datetime import datetime, timedelta

# Load env
# Load env
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(script_dir))
load_dotenv(os.path.join(project_root, 'backend', '.env'))

# Setup Gemini
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    GOOGLE_API_KEY = os.getenv("GEMINI_API_KEY")

if not GOOGLE_API_KEY:
    print("âŒ GOOGLE_API_KEY not found.")
    exit(1)

genai.configure(api_key=GOOGLE_API_KEY)
model = genai.GenerativeModel('gemini-2.5-flash-lite')

# Setup Supabase
url = os.getenv("NEXT_PUBLIC_SUPABASE_URL")
key = os.getenv("NEXT_PUBLIC_SUPABASE_ANON_KEY")

if not url or not key:
    print("âŒ Supabase credentials not found.")
    exit(1)

supabase: Client = create_client(url, key)

def fetch_article_titles(article_ids):
    """Fetch up to 3 article titles for context."""
    if not article_ids:
        return []
    try:
        # Limit to 3 IDs to avoid huge queries
        target_ids = article_ids[:3]
        response = supabase.table("mvp2_articles").select("title_ko, title_original").in_("id", target_ids).execute()
        titles = []
        for row in response.data:
            # Prefer Korean title, fallback to original
            t = row.get('title_ko') or row.get('title_original')
            if t:
                titles.append(t)
        return titles
    except Exception as e:
        print(f"    âš ï¸ Failed to fetch articles: {e}")
        return []

def generate_headline(title, context="", article_titles=[]):
    """
    Generate a witty, Newneek-style headline for a given title.
    """
    articles_context = ""
    if article_titles:
        articles_context = "\nRelated Articles (Use these for facts):\n" + "\n".join([f"- {t}" for t in article_titles])

    prompt = f"""
Role: Professional News Editor for Gen-Z (Newneek Style)
Task: Rewrite the following news title into a catchy, conversational, yet INFORMATIVE headline.

Original Title: {title}
Context: {context}{articles_context}

Rules:
1. Tone: Smart, friendly, and clear. Like a knowledgeable friend explaining the news.
2. Structure: Use "Hook: Summary" or "Fact + Context" structure.
3. Prohibition: Avoid vague clickbait questions (e.g., "Why is this happening?"). Explain WHAT is happening.
4. Prohibition: NEVER end with a noun (e.g., "ë…¼ë€", "ê°œìµœ"). Use complete sentences.
5. Prohibition: NO SENSATIONALISM. Do not use words like "ì¶©ê²©", "ë©˜ë¶•", "ê²½ì•…", "ì°", "ì•Œê³ ë³´ë‹ˆ". Stick to facts.
6. Length: Under 60 characters.
7. Language: Korean.
8. Emoji: Optional, max 1.

Examples (Good):
- "ìœ ë‹ˆí´ë¡œXë‹ˆë“¤ìŠ¤ í˜‘ì—…, ì™œ ì´ë ‡ê²Œ í™”ì œì¼ê¹Œ? ğŸ”¥: íŒ¨ìŠ¤íŠ¸ íŒ¨ì…˜ì´ ë§Œë“¤ì–´ê°€ëŠ” ìƒˆë¡œìš´ ì½œë¼ë³´ì˜ ì„¸ê³„"
- "445ì–µ ì› ê·œëª¨ ì—…ë¹„íŠ¸ í•´í‚¹ ì‚¬ê³ : ë°°í›„ì— ë¶í•œ í•´í‚¹ ì¡°ì§ì´ ìˆë‹¤ëŠ” ë§ì´ ë‚˜ì˜¤ëŠ” ì´ìœ "
- "ë²•ì›: â€œë°©í†µìœ„ì˜ ìœ ì§„ê·¸ë£¹ YTN ì¸ìˆ˜ ìŠ¹ì¸ ê²°ì •ì€ ì·¨ì†Œì•¼!â€ ğŸ§‘â€âš–ï¸"
- "ì„œìš¸ì˜í™”ì„¼í„° ê°œê´€, ë‚´ë…„ 3ì›”ê¹Œì§€ ì¶©ë¬´ë¡œì—ì„œ ê³µì§œ ì˜í™” ë³´ëŠ” ë²• ğŸ¥"

Examples (Bad - Avoid these styles):
- "ê¸°ìë“¤ ë©˜ë¶•ì‹œí‚¨ ì°: ì•Œê³  ë³´ë‹ˆ ì¶©ê²©ì  ì‚¬ì‹¤! ğŸ˜±" (Too clickbaity/YouTube style)
- "íŠ¸ëŸ¼í”„, ë§ˆì•½ ì „ ëŒ€í†µë ¹ í’€ì–´ì¤€ë‹¤ê³ ? ğŸ¤”" (Too vague)
- "í˜‘ë°•ë²” ì²´í¬ ì†Œì‹, ì™œ ë‚˜ë§Œ ëª°ë¼?" (Too personal/vague)

Output: Just the headline string.
"""
    try:
        response = model.generate_content(prompt)
        return response.text.strip().replace('"', '').replace("'", "")
    except Exception as e:
        print(f"    âš ï¸ Headline generation failed: {e}")
        return None

def process_megatopics():
    print("\nğŸŒ Processing Global Megatopics...")
    try:
        # Calculate 24 hours ago
        time_threshold = (datetime.utcnow() - timedelta(hours=24)).isoformat()
        
        response = supabase.table("mvp2_megatopics") \
            .select("*") \
            .gte("created_at", time_threshold) \
            .order("total_articles", desc=True) \
            .execute()
            
        topics = response.data
        print(f"Found {len(topics)} recent megatopics.")
        
        count = 0
        for t in topics:
            # Force regeneration
            # if t.get('headline'): continue
                
            print(f"  Generating headline for: {t['name']}")
            
            # Fetch representative articles from the first topic in this megatopic
            article_titles = []
            if t.get('topic_ids') and len(t['topic_ids']) > 0:
                # Get the first local topic to find article IDs
                first_topic_id = t['topic_ids'][0]
                topic_res = supabase.table("mvp2_topics").select("article_ids").eq("id", first_topic_id).execute()
                if topic_res.data and topic_res.data[0].get('article_ids'):
                    article_titles = fetch_article_titles(topic_res.data[0]['article_ids'])

            headline = generate_headline(t['name'], f"Keywords: {t.get('keywords', [])}", article_titles)
            if headline:
                print(f"    -> {headline}")
                supabase.table("mvp2_megatopics").update({"headline": headline}).eq("id", t['id']).execute()
                time.sleep(1) # Rate limit
                count += 1
            else:
                print("    -> Failed.")
        print(f"Generated {count} new headlines.")
                
    except Exception as e:
        print(f"âŒ Error processing megatopics: {e}")

def process_local_topics():
    print("\nğŸ‡°ğŸ‡· Processing Local Topics (KR)...")
    try:
        # Calculate 24 hours ago
        time_threshold = (datetime.utcnow() - timedelta(hours=24)).isoformat()
        
        response = supabase.table("mvp2_topics") \
            .select("*") \
            .eq("country_code", "KR") \
            .gte("created_at", time_threshold) \
            .order("article_count", desc=True) \
            .execute()
            
        topics = response.data
        print(f"Found {len(topics)} recent local topics.")
        
        count = 0
        for t in topics:
            # Force regeneration
            # if t.get('headline'): continue

            print(f"  Generating headline for: {t['topic_name']}")
            
            # Fetch articles
            article_titles = []
            if t.get('article_ids'):
                article_titles = fetch_article_titles(t['article_ids'])
            
            headline = generate_headline(t['topic_name'], f"Summary: {t.get('summary', '')}", article_titles)
            if headline:
                print(f"    -> {headline}")
                supabase.table("mvp2_topics").update({"headline": headline}).eq("id", t['id']).execute()
                time.sleep(1)
                count += 1
            else:
                print("    -> Failed.")
        print(f"Generated {count} new headlines.")

    except Exception as e:
        print(f"âŒ Error processing local topics: {e}")

def main():
    print("ğŸš€ Starting Headline Generator...")
    process_megatopics()
    process_local_topics()
    print("âœ… Headline Generation Complete.")

if __name__ == "__main__":
    main()
