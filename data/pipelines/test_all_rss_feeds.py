"""
RSS Feed Validation Script - ALL FEEDS
ì „ì²´ 52ê°œ ì–¸ë¡ ì‚¬ RSS í”¼ë“œë¥¼ ëª¨ë‘ í…ŒìŠ¤íŠ¸
"""

import feedparser
import json
from datetime import datetime
import time

# ë ˆê±°ì‹œ íŒŒì¼ì—ì„œ ê°€ì ¸ì˜¨ ì „ì²´ RSS í”¼ë“œ ëª©ë¡
ALL_RSS_FEEDS = {
    # ğŸ‡ºğŸ‡¸ ë¯¸êµ­ (5ê°œ)
    "US": [
        {"name": "New York Times", "url": "https://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml", "bias": "PROGRESSIVE"},
        {"name": "Washington Post", "url": "https://feeds.washingtonpost.com/rss/national", "bias": "PROGRESSIVE"},
        {"name": "Fox News", "url": "https://moxie.foxnews.com/google-publisher/latest.xml", "bias": "CONSERVATIVE"},
        {"name": "CNN", "url": "http://rss.cnn.com/rss/edition.rss", "bias": "NEUTRAL"},
        {"name": "The Hill", "url": "https://thehill.com/feed/", "bias": "NEUTRAL"},
    ],
    # ğŸ‡¬ğŸ‡§ ì˜êµ­ (6ê°œ)
    "GB": [
        {"name": "BBC", "url": "https://feeds.bbci.co.uk/news/rss.xml", "bias": "NEUTRAL"},
        {"name": "The Guardian", "url": "https://www.theguardian.com/uk/rss", "bias": "PROGRESSIVE"},
        {"name": "Financial Times", "url": "https://www.ft.com/rss/home", "bias": "NEUTRAL"},
        {"name": "The Independent", "url": "https://www.independent.co.uk/news/uk/rss", "bias": "PROGRESSIVE"},
        {"name": "Sky News", "url": "https://feeds.skynews.com/feeds/rss/home.xml", "bias": "NEUTRAL"},
        {"name": "The Telegraph", "url": "https://www.telegraph.co.uk/news/rss.xml", "bias": "CONSERVATIVE"},
    ],
    # ğŸ‡©ğŸ‡ª ë…ì¼ (4ê°œ)
    "DE": [
        {"name": "Der Spiegel", "url": "https://www.spiegel.de/schlagzeilen/index.rss", "bias": "PROGRESSIVE"},
        {"name": "FAZ", "url": "https://www.faz.net/rss/aktuell/", "bias": "CONSERVATIVE"},
        {"name": "SÃ¼ddeutsche Zeitung", "url": "https://rss.sueddeutsche.de/rss/Topthemen", "bias": "PROGRESSIVE"},
        {"name": "Deutsche Welle", "url": "https://rss.dw.com/rdf/rss-en-all", "bias": "NEUTRAL"},
    ],
    # ğŸ‡«ğŸ‡· í”„ë‘ìŠ¤ (4ê°œ)
    "FR": [
        {"name": "Le Monde", "url": "http://www.lemonde.fr/rss/une.xml", "bias": "PROGRESSIVE"},
        {"name": "Le Figaro", "url": "https://www.lefigaro.fr/rss/figaro_flash-actu.xml", "bias": "CONSERVATIVE"},
        {"name": "France 24", "url": "https://www.france24.com/en/rss", "bias": "NEUTRAL"},
        {"name": "Mediapart", "url": "https://www.mediapart.fr/articles/feed", "bias": "PROGRESSIVE"},
    ],
    # ğŸ‡®ğŸ‡¹ ì´íƒˆë¦¬ì•„ (2ê°œ)
    "IT": [
        {"name": "La Repubblica", "url": "https://www.repubblica.it/rss/homepage/rss2.0.xml", "bias": "PROGRESSIVE"},
        {"name": "Corriere della Sera", "url": "https://www.corriere.it/rss/homepage.xml", "bias": "CONSERVATIVE"},
    ],
    # ğŸ‡¯ğŸ‡µ ì¼ë³¸ (4ê°œ)
    "JP": [
        {"name": "Yomiuri Shimbun", "url": "https://japannews.yomiuri.co.jp/feed", "bias": "CONSERVATIVE"},
        {"name": "Nikkei Asia", "url": "https://asia.nikkei.com/rss/feed/nar", "bias": "NEUTRAL"},
        {"name": "NHK", "url": "https://www3.nhk.or.jp/rss/news/cat0.xml", "bias": "NEUTRAL"},
        {"name": "Asahi Shimbun", "url": "https://www.asahi.com/rss/asahi/newsheadlines.rdf", "bias": "PROGRESSIVE"},
    ],
    # ğŸ‡°ğŸ‡· í•œêµ­ (5ê°œ)
    "KR": [
        {"name": "Google News Korea", "url": "https://news.google.com/rss?hl=ko&gl=KR&ceid=KR:ko", "bias": "NEUTRAL"},
        {"name": "SBS", "url": "https://news.sbs.co.kr/news/TopicRssFeed.do?plink=RSSREADER", "bias": "NEUTRAL"},
        {"name": "ì¡°ì„ ì¼ë³´", "url": "https://www.chosun.com/arc/outboundfeeds/rss/?outputType=xml", "bias": "CONSERVATIVE"},
        {"name": "ë™ì•„ì¼ë³´", "url": "https://rss.donga.com/total.xml", "bias": "CONSERVATIVE"},
        {"name": "ê²½í–¥ì‹ ë¬¸", "url": "https://www.khan.co.kr/rss/rssdata/total_news.xml", "bias": "PROGRESSIVE"},
    ],
    # ğŸ‡¨ğŸ‡¦ ìºë‚˜ë‹¤ (5ê°œ)
    "CA": [
        {"name": "National Post", "url": "https://nationalpost.com/feed", "bias": "CONSERVATIVE"},
        {"name": "CBC", "url": "https://www.cbc.ca/cmlink/rss-topstories", "bias": "NEUTRAL"},
        {"name": "Globe and Mail - Business", "url": "https://www.theglobeandmail.com/arc/outboundfeeds/rss/category/business/", "bias": "NEUTRAL"},
        {"name": "Globe and Mail - Canada", "url": "https://www.theglobeandmail.com/arc/outboundfeeds/rss/category/canada/", "bias": "NEUTRAL"},
        {"name": "Globe and Mail - Politics", "url": "https://www.theglobeandmail.com/arc/outboundfeeds/rss/category/politics/", "bias": "NEUTRAL"},
    ],
    # ğŸ‡¦ğŸ‡º í˜¸ì£¼ (3ê°œ)
    "AU": [
        {"name": "ABC Australia", "url": "https://www.abc.net.au/news/feed/51120/rss.xml", "bias": "NEUTRAL"},
        {"name": "Sydney Morning Herald", "url": "https://www.smh.com.au/rss/feed.xml", "bias": "PROGRESSIVE"},
        {"name": "The Age", "url": "https://www.theage.com.au/rss/feed.xml", "bias": "PROGRESSIVE"},
    ],
    # ğŸ‡§ğŸ‡ª ë²¨ê¸°ì— (3ê°œ)
    "BE": [
        {"name": "La Libre", "url": "https://www.lalibre.be/rss.xml", "bias": "NEUTRAL"},
        {"name": "RTBF", "url": "https://rss.rtbf.be/article/rss/highlight_rtbf_info.xml?source=internal", "bias": "NEUTRAL"},
        {"name": "Le Soir", "url": "https://www.lesoir.be/rss2/2/cible_principale", "bias": "PROGRESSIVE"},
    ],
    # ğŸ‡³ğŸ‡± ë„¤ëœë€ë“œ (4ê°œ)
    "NL": [
        {"name": "NRC", "url": "https://www.nrc.nl/rss/", "bias": "PROGRESSIVE"},
        {"name": "De Telegraaf", "url": "https://www.telegraaf.nl/rss", "bias": "CONSERVATIVE"},
        {"name": "NOS", "url": "https://feeds.nos.nl/nosnieuwsalgemeen", "bias": "NEUTRAL"},
        {"name": "De Volkskrant", "url": "https://www.volkskrant.nl/voorpagina/rss.xml", "bias": "PROGRESSIVE"},
    ],
    # ğŸ‡·ğŸ‡º ëŸ¬ì‹œì•„ (4ê°œ)
    "RU": [
        {"name": "RT (Russia Today)", "url": "https://www.rt.com/rss/news/", "bias": "CONSERVATIVE"},
        {"name": "TASS", "url": "https://tass.com/rss/v2.xml", "bias": "CONSERVATIVE"},
        {"name": "Kommersant", "url": "https://www.kommersant.ru/RSS/news.xml", "bias": "NEUTRAL"},
        {"name": "Novaya Gazeta", "url": "https://novayagazeta.eu/feed/rss/en", "bias": "PROGRESSIVE"},
    ],
    # ğŸ‡¨ğŸ‡³ ì¤‘êµ­ (2ê°œ)
    "CN": [
        {"name": "Xinhua", "url": "http://www.xinhuanet.com/english/rss/chinarss.xml", "bias": "CONSERVATIVE"},
        {"name": "South China Morning Post", "url": "https://www.scmp.com/rss/91/feed", "bias": "NEUTRAL"},
    ],
}


def parse_rss_feed(url, timeout=30):
    """feedparserë¥¼ ì‚¬ìš©í•˜ì—¬ RSS í”¼ë“œ íŒŒì‹± (30ì´ˆ íƒ€ì„ì•„ì›ƒ)"""
    try:
        import signal
        
        def timeout_handler(signum, frame):
            raise TimeoutError(f"Feed parsing timeout after {timeout} seconds")
        
        # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(timeout)
        
        try:
            feed = feedparser.parse(url)
            signal.alarm(0)  # íƒ€ì„ì•„ì›ƒ í•´ì œ
        except TimeoutError as e:
            return {
                "success": False,
                "error": str(e)
            }
        
        if feed.bozo and not feed.entries:
            return {
                "success": False,
                "error": f"Parsing error: {feed.bozo_exception}"
            }
        
        if not feed.entries:
            return {
                "success": False,
                "error": "No entries found in feed"
            }
        
        # í”¼ë“œ ì •ë³´
        feed_title = feed.feed.get('title', 'Unknown Source')
        
        # ì²« ë²ˆì§¸ ì—”íŠ¸ë¦¬ íŒŒì‹±
        first_entry = feed.entries[0]
        
        # ì œëª©
        title = first_entry.get('title', 'No Title')
        
        # ë§í¬
        link = first_entry.get('link', '')
        
        # ë°œí–‰ì¼
        published = None
        if hasattr(first_entry, 'published'):
            published = first_entry.published
        elif hasattr(first_entry, 'updated'):
            published = first_entry.updated
        
        # Summary/Description
        summary = None
        summary_length = 0
        has_summary = False
        
        if hasattr(first_entry, 'summary'):
            summary = first_entry.summary
            summary_length = len(summary)
            has_summary = True
        elif hasattr(first_entry, 'description'):
            summary = first_entry.description
            summary_length = len(summary)
            has_summary = True
        elif hasattr(first_entry, 'content'):
            if first_entry.content:
                summary = first_entry.content[0].get('value', '')
                summary_length = len(summary)
                has_summary = True
        
        return {
            "success": True,
            "source_title": feed_title,
            "total_items": len(feed.entries),
            "has_summary": has_summary,
            "summary_length": summary_length,
            "sample_item": {
                "title": title[:100] + "..." if len(title) > 100 else title,
                "link": link[:100] + "..." if len(link) > 100 else link,
                "published_at": published,
                "summary_preview": summary[:100] + "..." if summary and len(summary) > 100 else summary,
                "summary_full_length": summary_length,
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"{type(e).__name__}: {str(e)}"
        }


def test_all_feeds():
    """ì „ì²´ 52ê°œ ì–¸ë¡ ì‚¬ RSS í”¼ë“œ í…ŒìŠ¤íŠ¸"""
    print("=" * 80)
    print("ğŸ” RSS Feed Validation Test - ALL 52 SOURCES")
    print("=" * 80)
    print()
    
    all_results = {}
    total_feeds = 0
    success_count = 0
    fail_count = 0
    feeds_with_summary = []
    feeds_without_summary = []
    failed_feeds = []
    
    for country_code, feeds in ALL_RSS_FEEDS.items():
        print(f"\n{'='*80}")
        print(f"ğŸŒ {country_code} - Testing {len(feeds)} sources")
        print(f"{'='*80}\n")
        
        country_results = []
        
        for feed_info in feeds:
            total_feeds += 1
            print(f"ğŸ“° {feed_info['name']} ({feed_info['bias']})")
            print(f"   URL: {feed_info['url']}")
            
            result = parse_rss_feed(feed_info['url'])
            
            feed_result = {
                "name": feed_info['name'],
                "bias": feed_info['bias'],
                "url": feed_info['url'],
                **result
            }
            
            country_results.append(feed_result)
            
            if result['success']:
                success_count += 1
                print(f"   âœ… SUCCESS - {result['total_items']} items")
                print(f"   ğŸ“„ Title: {result['sample_item']['title']}")
                
                if result['has_summary']:
                    print(f"   ğŸ“ Summary: âœ… YES ({result['summary_length']} chars)")
                    feeds_with_summary.append({
                        'country': country_code,
                        'name': feed_info['name'],
                        'summary_length': result['summary_length']
                    })
                else:
                    print(f"   ğŸ“ Summary: âŒ NO")
                    feeds_without_summary.append({
                        'country': country_code,
                        'name': feed_info['name']
                    })
            else:
                fail_count += 1
                print(f"   âŒ FAILED - {result['error']}")
                failed_feeds.append({
                    'country': country_code,
                    'name': feed_info['name'],
                    'error': result['error']
                })
            
            print()
            
            # ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
            time.sleep(0.5)
        
        all_results[country_code] = country_results
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "=" * 80)
    print("ğŸ“Š FINAL SUMMARY")
    print("=" * 80)
    print(f"Total Feeds Tested: {total_feeds}")
    print(f"âœ… Success: {success_count}/{total_feeds} ({success_count/total_feeds*100:.1f}%)")
    print(f"âŒ Failed: {fail_count}/{total_feeds} ({fail_count/total_feeds*100:.1f}%)")
    print()
    
    # Summary ë¶„ì„
    print("=" * 80)
    print("ğŸ“ Summary Field Analysis")
    print("=" * 80)
    print(f"âœ… Feeds WITH summary: {len(feeds_with_summary)}/{success_count} ({len(feeds_with_summary)/success_count*100:.1f}%)")
    print(f"âŒ Feeds WITHOUT summary: {len(feeds_without_summary)}/{success_count} ({len(feeds_without_summary)/success_count*100:.1f}%)")
    print()
    
    # êµ­ê°€ë³„ í†µê³„
    print("=" * 80)
    print("ğŸŒ By Country")
    print("=" * 80)
    for country_code, results in all_results.items():
        total = len(results)
        success = sum(1 for r in results if r['success'])
        with_summary = sum(1 for r in results if r.get('success') and r.get('has_summary'))
        print(f"{country_code}: {success}/{total} success, {with_summary}/{success} with summary" if success > 0 else f"{country_code}: {success}/{total} success")
    print()
    
    # ì‹¤íŒ¨í•œ í”¼ë“œ ìƒì„¸
    if failed_feeds:
        print("=" * 80)
        print("âš ï¸  Failed Feeds Details")
        print("=" * 80)
        for feed in failed_feeds:
            print(f"âŒ {feed['country']} - {feed['name']}")
            print(f"   Error: {feed['error']}")
        print()
    
    # Summary ì—†ëŠ” í”¼ë“œ ìƒì„¸
    if feeds_without_summary:
        print("=" * 80)
        print("ğŸ“ Feeds WITHOUT Summary")
        print("=" * 80)
        for feed in feeds_without_summary:
            print(f"- {feed['country']}: {feed['name']}")
        print()
    
    # JSON ì €ì¥
    output_file = "rss_feed_test_results_ALL.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ Results saved to: {output_file}")
    print()
    
    return all_results


if __name__ == "__main__":
    test_all_feeds()
