"""
RSS Feed Validation Script
ê° êµ­ê°€ë³„ë¡œ 1ê°œ ì–¸ë¡ ì‚¬ì”© RSS í”¼ë“œë¥¼ í…ŒìŠ¤íŠ¸í•˜ì—¬ ì •ìƒ ì‘ë™ ì—¬ë¶€ ë° ë°ì´í„° í˜•íƒœ í™•ì¸
"""

import requests
import xml.etree.ElementTree as ET
from datetime import datetime
import json

# ê° êµ­ê°€ë³„ 1ê°œ ì–¸ë¡ ì‚¬ë§Œ í…ŒìŠ¤íŠ¸ (ëŒ€í‘œ ì–¸ë¡ ì‚¬)
TEST_FEEDS = {
    "US": {
        "name": "CNN",
        "url": "http://rss.cnn.com/rss/edition.rss",
        "bias": "NEUTRAL"
    },
    "GB": {
        "name": "BBC",
        "url": "https://feeds.bbci.co.uk/news/rss.xml",
        "bias": "NEUTRAL"
    },
    "DE": {
        "name": "Deutsche Welle",
        "url": "https://rss.dw.com/rdf/rss-en-all",
        "bias": "NEUTRAL"
    },
    "FR": {
        "name": "France 24",
        "url": "https://www.france24.com/en/rss",
        "bias": "NEUTRAL"
    },
    "IT": {
        "name": "La Repubblica",
        "url": "https://www.repubblica.it/rss/homepage/rss2.0.xml",
        "bias": "PROGRESSIVE"
    },
    "JP": {
        "name": "NHK",
        "url": "https://www3.nhk.or.jp/rss/news/cat0.xml",
        "bias": "NEUTRAL"
    },
    "KR": {
        "name": "ì¡°ì„ ì¼ë³´",
        "url": "https://www.chosun.com/arc/outboundfeeds/rss/?outputType=xml",
        "bias": "CONSERVATIVE"
    },
    "CA": {
        "name": "CBC",
        "url": "https://www.cbc.ca/cmlink/rss-topstories",
        "bias": "NEUTRAL"
    },
    "AU": {
        "name": "ABC Australia",
        "url": "https://www.abc.net.au/news/feed/51120/rss.xml",
        "bias": "NEUTRAL"
    },
    "BE": {
        "name": "RTBF",
        "url": "https://rss.rtbf.be/article/rss/highlight_rtbf_info.xml?source=internal",
        "bias": "NEUTRAL"
    },
    "NL": {
        "name": "NOS",
        "url": "https://feeds.nos.nl/nosnieuwsalgemeen",
        "bias": "NEUTRAL"
    },
    "RU": {
        "name": "RT (Russia Today)",
        "url": "https://www.rt.com/rss/news/",
        "bias": "CONSERVATIVE"
    },
    "CN": {
        "name": "South China Morning Post",
        "url": "https://www.scmp.com/rss/91/feed",
        "bias": "NEUTRAL"
    }
}


def parse_rss_feed(url, timeout=30):
    """RSS í”¼ë“œë¥¼ íŒŒì‹±í•˜ì—¬ ì²« ë²ˆì§¸ ì•„ì´í…œì˜ êµ¬ì¡°ë¥¼ ë°˜í™˜"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }
        
        print(f"  ğŸ“¡ Fetching feed...")
        response = requests.get(url, headers=headers, timeout=timeout)
        response.raise_for_status()
        
        # XML íŒŒì‹±
        root = ET.fromstring(response.content)
        
        # channel ì°¾ê¸° (RSS 2.0)
        channel = root.find('channel')
        if channel is None:
            # RSS 1.0 ë˜ëŠ” Atom í˜•ì‹ì¼ ìˆ˜ ìˆìŒ
            channel = root
        
        # ì†ŒìŠ¤ ì œëª© ì¶”ì¶œ
        source_title = "Unknown Source"
        if channel is not None:
            title_elem = channel.find('title')
            if title_elem is not None and title_elem.text:
                source_title = title_elem.text
            else:
                # RSS 1.0 ë„¤ì„ìŠ¤í˜ì´ìŠ¤
                ns_title = channel.find('.//{http://purl.org/rss/1.0/}title')
                if ns_title is not None and ns_title.text:
                    source_title = ns_title.text
        
        # ì•„ì´í…œ ì°¾ê¸°
        items = channel.findall('item') if channel is not None else []
        if not items:
            items = root.findall('.//{http://purl.org/rss/1.0/}item')
        if not items:
            items = root.findall('.//item')
        
        if not items:
            return {
                "success": False,
                "error": "No items found in feed",
                "source_title": source_title,
                "total_items": 0
            }
        
        # ì²« ë²ˆì§¸ ì•„ì´í…œ íŒŒì‹±
        first_item = items[0]
        
        # ì œëª©
        title = (first_item.find('title') or first_item.find('.//{http://purl.org/rss/1.0/}title'))
        title = title.text if title is not None else "No Title"
        
        # ë§í¬
        link = (first_item.find('link') or first_item.find('.//{http://purl.org/rss/1.0/}link'))
        link = link.text if link is not None else ""
        
        # ë°œí–‰ì¼
        pub_date = (first_item.find('pubDate') or first_item.find('.//{http://purl.org/dc/elements/1.1/}date'))
        pub_date = pub_date.text if pub_date is not None else None
        
        # ì„¤ëª…/ìš”ì•½
        description = (first_item.find('description') or first_item.find('.//{http://purl.org/rss/1.0/}description'))
        description = description.text if description is not None else ""
        
        # ì¹´í…Œê³ ë¦¬
        categories = [cat.text for cat in first_item.findall('category') if cat.text]
        
        # ì‘ì„±ì
        author = first_item.find('author')
        author = author.text if author is not None else None
        
        return {
            "success": True,
            "source_title": source_title,
            "total_items": len(items),
            "sample_item": {
                "title": title[:100] + "..." if len(title) > 100 else title,
                "link": link,
                "published_at": pub_date,
                "description": description[:150] + "..." if description and len(description) > 150 else description,
                "categories": categories,
                "author": author
            }
        }
        
    except requests.exceptions.Timeout:
        return {
            "success": False,
            "error": "Request timeout (30s)"
        }
    except requests.exceptions.RequestException as e:
        return {
            "success": False,
            "error": f"Request error: {type(e).__name__}: {str(e)}"
        }
    except ET.ParseError as e:
        return {
            "success": False,
            "error": f"XML parsing error: {str(e)}"
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"Unexpected error: {type(e).__name__}: {str(e)}"
        }


def test_all_feeds():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ í”¼ë“œë¥¼ ê²€ì¦"""
    print("=" * 80)
    print("ğŸ” RSS Feed Validation Test")
    print("=" * 80)
    print()
    
    results = {}
    success_count = 0
    fail_count = 0
    
    for country_code, feed_info in TEST_FEEDS.items():
        print(f"ğŸŒ {country_code} - {feed_info['name']} ({feed_info['bias']})")
        print(f"   URL: {feed_info['url']}")
        
        result = parse_rss_feed(feed_info['url'])
        results[country_code] = {
            "name": feed_info['name'],
            "bias": feed_info['bias'],
            "url": feed_info['url'],
            **result
        }
        
        if result['success']:
            success_count += 1
            print(f"   âœ… SUCCESS - {result['total_items']} items found")
            print(f"   ğŸ“° Source: {result['source_title']}")
            print(f"   ğŸ“„ Sample Title: {result['sample_item']['title']}")
            if result['sample_item']['published_at']:
                print(f"   ğŸ“… Published: {result['sample_item']['published_at']}")
        else:
            fail_count += 1
            print(f"   âŒ FAILED - {result['error']}")
        
        print()
    
    # ìš”ì•½
    print("=" * 80)
    print("ğŸ“Š Summary")
    print("=" * 80)
    print(f"âœ… Success: {success_count}/{len(TEST_FEEDS)}")
    print(f"âŒ Failed: {fail_count}/{len(TEST_FEEDS)}")
    print()
    
    # ì‹¤íŒ¨í•œ í”¼ë“œ ëª©ë¡
    if fail_count > 0:
        print("âš ï¸  Failed Feeds:")
        for country_code, result in results.items():
            if not result['success']:
                print(f"   - {country_code}: {result['name']}")
                print(f"     Error: {result['error']}")
        print()
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    output_file = "rss_feed_test_results.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ Results saved to: {output_file}")
    print()
    
    return results


if __name__ == "__main__":
    test_all_feeds()
