"""
RSS Feed Validation Script v2
- ê° êµ­ê°€ë³„ë¡œ 1ê°œ ì–¸ë¡ ì‚¬ì”© RSS í”¼ë“œë¥¼ í…ŒìŠ¤íŠ¸
- summary/description í•„ë“œê°€ ìˆëŠ” í”¼ë“œë¥¼ ëª¨ë‘ ê¸°ë¡
- feedparser ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©ìœ¼ë¡œ íŒŒì‹± ê°œì„ 
"""

import feedparser
import json
from datetime import datetime

# ê° êµ­ê°€ë³„ 1ê°œ ì–¸ë¡ ì‚¬ë§Œ í…ŒìŠ¤íŠ¸ (ëŒ€í‘œ ì–¸ë¡ ì‚¬)
TEST_FEEDS = {
    "US": {
        "name": "CNN",
        "url": "http://rss.cnn.com/rss/edition.rss",
        "bias": "NEUTRAL"
    },
    "GB": {
        "name": "BBC",
        "url": "https://feeds.bbci.co.uk/news/rss.xml",
        "bias": "NEUTRAL"
    },
    "DE": {
        "name": "Deutsche Welle",
        "url": "https://rss.dw.com/rdf/rss-en-all",
        "bias": "NEUTRAL"
    },
    "FR": {
        "name": "France 24",
        "url": "https://www.france24.com/en/rss",
        "bias": "NEUTRAL"
    },
    "IT": {
        "name": "La Repubblica",
        "url": "https://www.repubblica.it/rss/homepage/rss2.0.xml",
        "bias": "PROGRESSIVE"
    },
    "JP": {
        "name": "NHK",
        "url": "https://www3.nhk.or.jp/rss/news/cat0.xml",
        "bias": "NEUTRAL"
    },
    "KR": {
        "name": "ì¡°ì„ ì¼ë³´",
        "url": "https://www.chosun.com/arc/outboundfeeds/rss/?outputType=xml",
        "bias": "CONSERVATIVE"
    },
    "CA": {
        "name": "CBC",
        "url": "https://www.cbc.ca/cmlink/rss-topstories",
        "bias": "NEUTRAL"
    },
    "AU": {
        "name": "ABC Australia",
        "url": "https://www.abc.net.au/news/feed/51120/rss.xml",
        "bias": "NEUTRAL"
    },
    "BE": {
        "name": "RTBF",
        "url": "https://rss.rtbf.be/article/rss/highlight_rtbf_info.xml?source=internal",
        "bias": "NEUTRAL"
    },
    "NL": {
        "name": "NOS",
        "url": "https://feeds.nos.nl/nosnieuwsalgemeen",
        "bias": "NEUTRAL"
    },
    "RU": {
        "name": "RT (Russia Today)",
        "url": "https://www.rt.com/rss/news/",
        "bias": "CONSERVATIVE"
    },
    "CN": {
        "name": "South China Morning Post",
        "url": "https://www.scmp.com/rss/91/feed",
        "bias": "NEUTRAL"
    }
}


def parse_rss_feed_v2(url, timeout=30):
    """feedparserë¥¼ ì‚¬ìš©í•˜ì—¬ RSS í”¼ë“œ íŒŒì‹±"""
    try:
        print(f"  ğŸ“¡ Fetching feed with feedparser...")
        
        # feedparser ì‚¬ìš© (ëª¨ë“  RSS/Atom í˜•ì‹ ìë™ ì²˜ë¦¬)
        feed = feedparser.parse(url)
        
        if feed.bozo:
            # íŒŒì‹± ì—ëŸ¬ê°€ ìˆì§€ë§Œ ì¼ë¶€ ë°ì´í„°ëŠ” ìˆì„ ìˆ˜ ìˆìŒ
            print(f"  âš ï¸  Warning: Feed has parsing issues - {feed.bozo_exception}")
        
        if not feed.entries:
            return {
                "success": False,
                "error": "No entries found in feed"
            }
        
        # í”¼ë“œ ì •ë³´
        feed_title = feed.feed.get('title', 'Unknown Source')
        
        # ì²« ë²ˆì§¸ ì—”íŠ¸ë¦¬ íŒŒì‹±
        first_entry = feed.entries[0]
        
        # ì œëª©
        title = first_entry.get('title', 'No Title')
        
        # ë§í¬
        link = first_entry.get('link', '')
        
        # ë°œí–‰ì¼ (ì—¬ëŸ¬ í˜•ì‹ ì‹œë„)
        published = None
        if hasattr(first_entry, 'published'):
            published = first_entry.published
        elif hasattr(first_entry, 'updated'):
            published = first_entry.updated
        
        # Summary/Description (ì—¬ëŸ¬ í•„ë“œ ì‹œë„)
        summary = None
        summary_length = 0
        has_summary = False
        
        if hasattr(first_entry, 'summary'):
            summary = first_entry.summary
            summary_length = len(summary)
            has_summary = True
        elif hasattr(first_entry, 'description'):
            summary = first_entry.description
            summary_length = len(summary)
            has_summary = True
        elif hasattr(first_entry, 'content'):
            if first_entry.content:
                summary = first_entry.content[0].get('value', '')
                summary_length = len(summary)
                has_summary = True
        
        # ì¹´í…Œê³ ë¦¬
        categories = []
        if hasattr(first_entry, 'tags'):
            categories = [tag.get('term', '') for tag in first_entry.tags]
        
        # ì‘ì„±ì
        author = first_entry.get('author', None)
        
        # ë¯¸ë””ì–´ (ì´ë¯¸ì§€/ë¹„ë””ì˜¤)
        media = []
        if hasattr(first_entry, 'media_content'):
            for m in first_entry.media_content:
                media.append({
                    'url': m.get('url', ''),
                    'type': m.get('type', ''),
                    'medium': m.get('medium', '')
                })
        
        return {
            "success": True,
            "source_title": feed_title,
            "total_items": len(feed.entries),
            "has_summary": has_summary,
            "summary_length": summary_length,
            "sample_item": {
                "title": title[:100] + "..." if len(title) > 100 else title,
                "link": link,
                "published_at": published,
                "summary": summary[:200] + "..." if summary and len(summary) > 200 else summary,
                "summary_full_length": summary_length,
                "categories": categories,
                "author": author,
                "media": media[:2] if media else []  # ì²˜ìŒ 2ê°œë§Œ
            }
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"Unexpected error: {type(e).__name__}: {str(e)}"
        }


def test_all_feeds_v2():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ í”¼ë“œë¥¼ ê²€ì¦ (v2)"""
    print("=" * 80)
    print("ğŸ” RSS Feed Validation Test v2 (with feedparser)")
    print("=" * 80)
    print()
    
    results = {}
    success_count = 0
    fail_count = 0
    feeds_with_summary = []
    feeds_without_summary = []
    
    for country_code, feed_info in TEST_FEEDS.items():
        print(f"ğŸŒ {country_code} - {feed_info['name']} ({feed_info['bias']})")
        print(f"   URL: {feed_info['url']}")
        
        result = parse_rss_feed_v2(feed_info['url'])
        results[country_code] = {
            "name": feed_info['name'],
            "bias": feed_info['bias'],
            "url": feed_info['url'],
            **result
        }
        
        if result['success']:
            success_count += 1
            print(f"   âœ… SUCCESS - {result['total_items']} items found")
            print(f"   ğŸ“° Source: {result['source_title']}")
            print(f"   ğŸ“„ Title: {result['sample_item']['title']}")
            
            if result['has_summary']:
                print(f"   ğŸ“ Summary: âœ… YES ({result['summary_length']} chars)")
                feeds_with_summary.append({
                    'country': country_code,
                    'name': feed_info['name'],
                    'summary_length': result['summary_length']
                })
            else:
                print(f"   ğŸ“ Summary: âŒ NO")
                feeds_without_summary.append({
                    'country': country_code,
                    'name': feed_info['name']
                })
            
            if result['sample_item']['published_at']:
                print(f"   ğŸ“… Published: {result['sample_item']['published_at']}")
            
            if result['sample_item']['media']:
                print(f"   ğŸ–¼ï¸  Media: {len(result['sample_item']['media'])} items")
        else:
            fail_count += 1
            print(f"   âŒ FAILED - {result['error']}")
        
        print()
    
    # ìš”ì•½
    print("=" * 80)
    print("ğŸ“Š Summary")
    print("=" * 80)
    print(f"âœ… Success: {success_count}/{len(TEST_FEEDS)}")
    print(f"âŒ Failed: {fail_count}/{len(TEST_FEEDS)}")
    print()
    
    # Summary í•„ë“œ ë¶„ì„
    print("=" * 80)
    print("ğŸ“ Summary Field Analysis")
    print("=" * 80)
    print(f"âœ… Feeds WITH summary: {len(feeds_with_summary)}/{success_count}")
    for feed in feeds_with_summary:
        print(f"   - {feed['country']}: {feed['name']} ({feed['summary_length']} chars)")
    print()
    
    print(f"âŒ Feeds WITHOUT summary: {len(feeds_without_summary)}/{success_count}")
    for feed in feeds_without_summary:
        print(f"   - {feed['country']}: {feed['name']}")
    print()
    
    # ì‹¤íŒ¨í•œ í”¼ë“œ ëª©ë¡
    if fail_count > 0:
        print("âš ï¸  Failed Feeds:")
        for country_code, result in results.items():
            if not result['success']:
                print(f"   - {country_code}: {result['name']}")
                print(f"     Error: {result['error']}")
        print()
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    output_file = "rss_feed_test_results_v2.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ Results saved to: {output_file}")
    print()
    
    return results


if __name__ == "__main__":
    test_all_feeds_v2()
